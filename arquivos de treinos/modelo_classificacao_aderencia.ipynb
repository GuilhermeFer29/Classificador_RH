{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- Preparação para o modelo de classificação -----\n",
    "\n",
    "# Dividir em conjuntos de treino e teste\n",
    "X = aplicacoes_df.drop(['Aderente', 'CandidatoID', 'VagaID', 'Score_Total'], axis=1)\n",
    "y = aplicacoes_df['Aderente']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocessamento\n",
    "numeric_features = ['Idade', 'Anos_Experiencia', 'Experiencia_Minima_Vaga', \n",
    "                    'Match_Habilidades', 'Match_Soft_Skills', 'Match_Experiencia', \n",
    "                    'Match_Salario', 'Match_Area']\n",
    "categorical_features = ['Nivel_Formacao', 'Nivel_Vaga']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Criar e treinar o modelo\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidade da classe positiva\n",
    "\n",
    "# Métricas de avaliação\n",
    "print(\"\\n----- Avaliação do Modelo -----\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.savefig('matriz_confusao.png')\n",
    "plt.close()\n",
    "\n",
    "# Importância das features\n",
    "if hasattr(model[-1], 'feature_importances_'):\n",
    "    # Obter nomes das colunas após transformação\n",
    "    ohe_features = []\n",
    "    if hasattr(model[0], 'transformers_'):\n",
    "        for name, _, column_names in model[0].transformers_:\n",
    "            if name == 'cat':\n",
    "                for col in column_names:\n",
    "                    categories = model[0].named_transformers_[name]['onehot'].categories_[0]\n",
    "                    for cat in categories:\n",
    "                        ohe_features.append(f\"{col}_{cat}\")\n",
    "            else:\n",
    "                ohe_features.extend(column_names)\n",
    "    \n",
    "    # Usar os nomes originais se não conseguir encontrar os transformados\n",
    "    if not ohe_features:\n",
    "        ohe_features = X.columns\n",
    "    \n",
    "    # Importância das features\n",
    "    feature_importances = model[-1].feature_importances_\n",
    "    \n",
    "    # Plotar importância das features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    indices = np.argsort(feature_importances)[::-1]\n",
    "    top_indices = indices[:min(len(indices), 10)]  # Top 10 features\n",
    "    \n",
    "    plt.bar(range(len(top_indices)), feature_importances[top_indices])\n",
    "    plt.xticks(range(len(top_indices)), [ohe_features[i] if i < len(ohe_features) else f\"feature_{i}\" for i in top_indices], rotation=45, ha='right')\n",
    "    plt.title('Top 10 Features mais Importantes')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "\n",
    "# Salvar o modelo para uso posterior\n",
    "joblib.dump(model, 'modelo_aderencia_candidatos.joblib')\n",
    "print(\"\\nModelo salvo como 'modelo_aderencia_candidatos.joblib'\")\n",
    "\n",
    "# ----- Criação de uma função para utilizar o modelo treinado -----\n",
    "def classificar_candidato_para_vaga(candidato_dict, vaga_dict, modelo):\n",
    "    ...\n",
    "\n",
    "# ----- Exemplo de uso do modelo -----\n",
    "print(\"\\n----- Exemplo de uso do modelo -----\")\n",
    "modelo_carregado = joblib.load('modelo_aderencia_candidatos.joblib')\n",
    "candidato_teste = candidatos_df.sample(1).iloc[0].to_dict()\n",
    "vaga_teste = vagas_df.sample(1).iloc[0].to_dict()\n",
    "print(f\"Candidato: {candidato_teste['Nome']} - {candidato_teste['Formacao']}\")\n",
    "print(f\"Vaga: {vaga_teste['Titulo']} - {vaga_teste['Empresa']}\")\n",
    "resultado = classificar_candidato_para_vaga(candidato_teste, vaga_teste, modelo_carregado)\n",
    "print(f\"Resultado: {resultado}\")\n",
    "\n",
    "# ----- Função para recomendação de vagas para um candidato -----\n",
    "def recomendar_vagas_para_candidato(candidato_dict, todas_vagas_df, modelo, top_n=5):\n",
    "    ...\n",
    "candidato_recomendacao = candidatos_df.sample(1).iloc[0].to_dict()\n",
    "amostra_vagas = vagas_df.sample(100)\n",
    "recomendacoes = recomendar_vagas_para_candidato(candidato_recomendacao, amostra_vagas, modelo_carregado, top_n=5)\n",
    "print(recomendacoes)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}